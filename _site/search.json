[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "Motivation\nThe motivation for this project stems from the urgent need to combat illegal fishing activities in the sensitive marine ecosystem of Oceanus. FishEye International aims to protect this environment by monitoring and analyzing business activities of commercial fishing operators. This project seeks to enhance the ability of FishEye’s analysts to visualize and understand complex business networks, and further aiding in the detection and prevention of illegal fishing.\n\n\nObjectives\nThis project aims to build an interactive visualization tool to enable FishEye’s analysts to effectively interpret the following changes related to illegal fishing on the business community:\n\nTemporal patterns and corporate structures: Highlight temporal patterns and corporate structures changes for analysts to track shareholders over time.\nBusiness Transactions: Identify typical and atypical business transactions and infer the motivations behind these activities.\nNetwork Influence: Examine how the influence of a company changes over time within the business network.\nSouthSeafood Express Corp Network: Visualize the network associated with SouthSeafood Express Corp and analyze how the network have changed due to the illegal fishing incident. Identify companies that benefited from SouthSeafood Express Corp’s legal troubles and potentially related transactions.\n\n\n\nData\nThe project will examine the data from VAST Challenge 2024 Mini-Challenge 3. The data contains the network for Oceanus’s commercial fishing business community. It contains 60,520 nodes, 75,817 edges, and 4,782 connected components.\nEach node represents the entities in the fishing business community (including people and organizations). The edges represent the relationship or transactions between each pair of connected nodes.\n\n\nMethodology\n\nDiagramExplanation\n\n\n\n\n\n\n\nflowchart TB\n  A[Data Wrangling]\n  B[Visualizing corporate structures]\n  C[Visualizing temporal changes]\n  D(Extracting subnetworks)\n  E(Extracting network state through time)\n  F[[Identifying influential nodes]]\n  G[[Identifying business transactions]]\n  H[Transforming graph for statistical analysis]\n  I[Calculate measures of centrality]\n  J[Visualizing influential nodes]\n  \n  subgraph Data Preparation\n    A -.-&gt; D\n    A -.-&gt; E\n  end\n  \n  A --&gt; B\n  D --&gt; B\n  E --&gt; C\n  A --&gt; C\n  F --&gt; H\n  \n  subgraph Data Exploration & Visualization\n    B --&gt; F\n    B --&gt; G\n    C --&gt; G\n    C --&gt; F\n  end\n  \n  subgraph Statistical Analysis\n    H --&gt; I\n    I --&gt; J\n  end\n\n\n\n\n\n\n\n\n\nData Preparation: Cleaning and shaping data to what is needed for analysis.\n\nNetwork and temporal data to enable getting the network state at any given time.\nNon-network data for accompanying information, if needed (e.g. products and services)\nWriting helper functions to generate the following subgraphs for closer analysis\n\nGetting subgraph based on proximity to a given node\nGetting the network state, i.e. nodes and edges present at any given time.\n\n\nData Exploration & Visualization: To identify patterns in the network and derive inferences from them.\n\nInteractive network graphs to see relationship between entities\nShiny app for users to interact and change parameters for analysis\n\nA time slider will be provided to easily see how the network changes through time\n\nBy looking at various network structures, identify the following:\n\nKinds of business transactions\nInfluential nodes\n\n\nStatistical Analysis: To test and evaluate or hypothesis.\n\nTransform network graph to power graph (as the provided graph may not be suitable for statistical analysis.\nCalculate measures of centrality to identify influential nodes\n\npagerank centrality for the nodes that hold the most power over resources in the network (the power holders).\nbetweenness centrality for the nodes the broker the power of a powerful node over the less powerful ones.\n\n\n\n\n\n\n\n\nPrototype Sketches\n\nTemporal patterns and corporate structures:\nCreate detailed feature timelines that cover various time periods, such as monthly, quarterly, and yearly intervals. These timelines should be meticulously organized to allow analysts to track changes and trends over time effectively. In addition, integrate the corresponding company structures into these timelines to provide a comprehensive view. This integration helps analysts understand the context behind the data and correlating features with organizational changes. By binding the timelines with company structures, analysts can easily identify patterns, pinpoint causes of anomalies, and make informed predictions.\nBusiness Transactions:\nConvert transactions into embeddings using a Large Language Model (LLM) or another suitable encoding framework. This process involves transforming transactional data into a format that captures its semantic and contextual meaning, making it easier to analyze and interpret. Once the transactions are embedded, apply advanced anomaly detection techniques to identify unusual patterns or deviations from expected behavior. These anomalies might indicate potential issues, fraudulent activities, or areas requiring further investigation.\nTo understand the motivations behind these anomalies, leverage business heuristics and insights derived from the LLM interpretations. This combined approach ensures a thorough examination of anomalies, enabling more accurate and actionable insights into the underlying motivations and potential implications for the business.\nNetwork Influence:\nGiven some specific companies, construct its business network by mapping out the relationships and interactions between various entities. Utilize data sources to construct these connections. Once the network is established, plot the network to visualize the impact of each entity within the network. This visualization helps identify central nodes and influential entities that significantly affect the company’s operations and strategic decisions.\nSouthSeafood Express Corp Network:\nBased on the previously constructed business network, identify the relevant companies involved in the illegal fishing activity. Begin by analyzing the network to spot entities with suspicious patterns or connections that suggest involvement in illegal practices.\nOnce the potentially involved companies are identified, delve into their transaction histories to uncover detailed evidence of their involvement. We can thus map out the methods and routes used for illegal fishing operations.\n\n\n\nR Packages\n\ntidyverse: A collection of R packages used in data science, which includes ggplot2, tibble, readr\nvistime: For visualizing timelines\nggraph: Extension of ggplot2 for plotting relational data\nvisNetwork: For plotting interactive network visualizations, compatible with Shiny\njsonlite: For parsing JSON data\n\n\n\nProject Schedule\n\n\nShow code\npacman::p_load(vistime, ggplot2)\ndata &lt;- read.csv(text=\"event,group,start,end,color\n                       ,Project Proposal,2024-05-12,2024-05-26,#a5d6a7\n                       ,Exploratory data analysis,2024-05-12,2024-05-26,#a5d6a7\n                       ,Exploratory data analysis,2024-05-26,2024-06-16,#DD4B39\n                       ,R Quarto/ Netlify,2024-05-12,2024-05-26,#a5d6a7\n                       ,R Quarto/ Netlify,2024-05-26,2024-06-30,#DD4B39\n                       ,R Shiny App,2024-05-26,2024-06-30,#DD4B39\n                       ,Poster,2024-06-16,2024-06-30,#DD4B39\n                       ,User Guide,2024-06-20,2024-06-30,#DD4B39\"\n                 )\n                \nproposal_deadline &lt;- as.Date(\"2024-05-26\") \n\np &lt;- gg_vistime(data, title = \"Project Timeline\") \np +\n  geom_vline(xintercept = as.numeric(as.POSIXct(\"2024-05-26\")), color = \"red\", size = 1)"
  },
  {
    "objectID": "meeting_minutes.html",
    "href": "meeting_minutes.html",
    "title": "Meeting Minutes",
    "section": "",
    "text": "Date: 13/05/2024\nTime: 9:00 - 9:30PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nDiscussion on project topic\nAction Items\n\n\n\n\n\nPrior to the meeting, we have agreed on reading the different challenges from VAST Challenge 2024 so that we can each choose our preference.\nWe disagreed on the challenge to do as Fengji prefers MC1, while Kristine prefers MC3.\nWe have a headstart with MC1 as techniques for Text Data Analysis were already covered in class.\nHowever, Kristine raised the issue of lack of knowledge in how to identify bias in the text data.\nWe also talked about the gap in what the different challenges require vs our own knowledge, e.g., how to detect bias, anomalies in geographic data.\n\n\n\n\n\nWe were not able to decide on the topic on this meeting and decided to reconvene during the next class (18/05).\nRead on the challenges again and research on the knowledge gaps we discovered.\n\n\n\n\n\n\n\n\n\n\n\nThis is just a short meeting during the break in class.\n\n\n\nDate: 18/05/2024\nTime: 2:15 - 2:25 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nDecide on project topic\nDivision of tasks for Project Proposal.\n\n\n\n\n\nWe agreed to go with MC3. We think that this is the challenge we can accomplish with our own knowledge and those taught in class.\n\n\n\n\nWe looked at the seniors’ work so that we can base on our Project Proposal on from those.\n\nWe divided the work for the proposal as follows:\n\nFengji: Motivation, Objectives, Problem Statement, Project Schedule\nKristine: Data, Methodology, Github and Netlify setup\nShared: Project Sketches, R Package list\n\nFurthermore, for Take-home Ex3, we decided on the following:\n\nFengji: Questions 1 & 2\nKristine: Questions 3 & 4\n\n\nIf we have enough time, we will do 1 more question so that we can compare notes on the overlapping question.\n\n\n\n\nDate: 22/05/2024\nTime: 4:30 - 5:00 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nProposal Check-in\nAction Items\n\n\n\n\n\nIt was only a few days before the proposal is due so we checked on each other’s progress.\n\nWe both have our parts ready by EoD.\n\nKristine updated that she won’t be available on Sunday (when the proposal is due).\nWe decided to drop the Problem Statement part as it is redundant with the Objectives.\nWe also decided for Prototype Sketches to be optional as we are not familiar how it will look in the Shiny app. Alternative is to just provide sketches based on normal visualizations.\nOur main blocker in creating the proposal is the lack of details that we cannot uncover unless we start doing the project.\n\n\n\n\n\nPush our work on the Project Proposal to Github so that we can check each other’s work.\nFengji to take care of submission on Sunday as Kristine will be out.\n\n\n\n\n\nDate: 22/06/2024\nTime: 9:00 - 9:30 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nProject Check-in\nTask Prioritization\n\n\n\n\n\nWe have only been communicating by Teams in the last month as we focused on Take-Home Exam 3.\nAfter that, we independently studied how to convert our Take Home Exam 3 outputs to Shiny App.\n\nWe had more pressing deadlines in other modules so we agreed to prioritize those first.\n\n\n\n\n\n\nThe items we still need to do for the project are:\n\nProject Site\n\nAdd prototype sketches\nAdd details on methodology\nPolish content\n\nPoster\nShiny App\n\nCombine our work\n\n\nWe decided to prioritize combining our Shiny Apps as we need the screenshots for the poster.\n\nSame with the Project Site, we will use Joy’s Github to collaborate on the Shiny App\nSubmitting the poster on Wednesday, June 26 is the highest priority\nMeet again on June 25 evening to finalize the poster."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-1",
    "href": "meeting_minutes.html#project-meeting-1",
    "title": "Meeting Minutes",
    "section": "",
    "text": "Date: 13/05/2024\nTime: 9:00 - 9:30PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nDiscussion on project topic\nAction Items\n\n\n\n\n\nPrior to the meeting, we have agreed on reading the different challenges from VAST Challenge 2024 so that we can each choose our preference.\nWe disagreed on the challenge to do as Fengji prefers MC1, while Kristine prefers MC3.\nWe have a headstart with MC1 as techniques for Text Data Analysis were already covered in class.\nHowever, Kristine raised the issue of lack of knowledge in how to identify bias in the text data.\nWe also talked about the gap in what the different challenges require vs our own knowledge, e.g., how to detect bias, anomalies in geographic data.\n\n\n\n\n\nWe were not able to decide on the topic on this meeting and decided to reconvene during the next class (18/05).\nRead on the challenges again and research on the knowledge gaps we discovered."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-2",
    "href": "meeting_minutes.html#project-meeting-2",
    "title": "Meeting Minutes",
    "section": "",
    "text": "This is just a short meeting during the break in class.\n\n\n\nDate: 18/05/2024\nTime: 2:15 - 2:25 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nDecide on project topic\nDivision of tasks for Project Proposal.\n\n\n\n\n\nWe agreed to go with MC3. We think that this is the challenge we can accomplish with our own knowledge and those taught in class.\n\n\n\n\nWe looked at the seniors’ work so that we can base on our Project Proposal on from those.\n\nWe divided the work for the proposal as follows:\n\nFengji: Motivation, Objectives, Problem Statement, Project Schedule\nKristine: Data, Methodology, Github and Netlify setup\nShared: Project Sketches, R Package list\n\nFurthermore, for Take-home Ex3, we decided on the following:\n\nFengji: Questions 1 & 2\nKristine: Questions 3 & 4\n\n\nIf we have enough time, we will do 1 more question so that we can compare notes on the overlapping question."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-3",
    "href": "meeting_minutes.html#project-meeting-3",
    "title": "Meeting Minutes",
    "section": "",
    "text": "Date: 22/05/2024\nTime: 4:30 - 5:00 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nProposal Check-in\nAction Items\n\n\n\n\n\nIt was only a few days before the proposal is due so we checked on each other’s progress.\n\nWe both have our parts ready by EoD.\n\nKristine updated that she won’t be available on Sunday (when the proposal is due).\nWe decided to drop the Problem Statement part as it is redundant with the Objectives.\nWe also decided for Prototype Sketches to be optional as we are not familiar how it will look in the Shiny app. Alternative is to just provide sketches based on normal visualizations.\nOur main blocker in creating the proposal is the lack of details that we cannot uncover unless we start doing the project.\n\n\n\n\n\nPush our work on the Project Proposal to Github so that we can check each other’s work.\nFengji to take care of submission on Sunday as Kristine will be out."
  },
  {
    "objectID": "meeting_minutes.html#project-meeting-4",
    "href": "meeting_minutes.html#project-meeting-4",
    "title": "Meeting Minutes",
    "section": "",
    "text": "Date: 22/06/2024\nTime: 9:00 - 9:30 PM\nIn Attendance: Kristine Joy Paas, Tan Fengji\n\n\n\nProject Check-in\nTask Prioritization\n\n\n\n\n\nWe have only been communicating by Teams in the last month as we focused on Take-Home Exam 3.\nAfter that, we independently studied how to convert our Take Home Exam 3 outputs to Shiny App.\n\nWe had more pressing deadlines in other modules so we agreed to prioritize those first.\n\n\n\n\n\n\nThe items we still need to do for the project are:\n\nProject Site\n\nAdd prototype sketches\nAdd details on methodology\nPolish content\n\nPoster\nShiny App\n\nCombine our work\n\n\nWe decided to prioritize combining our Shiny Apps as we need the screenshots for the poster.\n\nSame with the Project Site, we will use Joy’s Github to collaborate on the Shiny App\nSubmitting the poster on Wednesday, June 26 is the highest priority\nMeet again on June 25 evening to finalize the poster."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Big Fish: Catching Illegal Fishers Using Visual Analytics",
    "section": "",
    "text": "As part of VAST Challenge 2024, we will investigate the fishing business network of Oceanus. A network of businesses have recently been caught illegal fishing. FishEye, a non-profit organization collects various data about illegal fishing and our tasks is to develop data visualizations from data provided.\n\n\n\n\n\nWe will focus on Mini-challenge 3, which looks at the network data to investigate changes in corporate structures within the fishing business community. We will also look at the influence of different entities in the network to identify the entities that benefit from illegal fishing activities. Can we catch the big fish?"
  },
  {
    "objectID": "methodology/data_preparation.html",
    "href": "methodology/data_preparation.html",
    "title": "Data Preparation",
    "section": "",
    "text": "This document will go through how we prepare the data that will be used for the Shiny application."
  },
  {
    "objectID": "methodology/data_preparation.html#loading-packages",
    "href": "methodology/data_preparation.html#loading-packages",
    "title": "Data Preparation",
    "section": "1.1 Loading Packages",
    "text": "1.1 Loading Packages\nWe will use the following packages to prepare the data.\n\njsonlite - To parse JSON\nknitr - For better table displays\ntidyverse - Data science tools\ntidygraph - For graph manipulations\nigraph - Contains functions for network analysis\n\n\npacman::p_load(jsonlite, knitr, tidyverse, tidygraph, igraph)"
  },
  {
    "objectID": "methodology/data_preparation.html#loading-data",
    "href": "methodology/data_preparation.html#loading-data",
    "title": "Data Preparation",
    "section": "1.2 Loading Data",
    "text": "1.2 Loading Data\nWe will load the provided VAST Mini-Challenge 3 dataset, a json file.\n\nmc3_data &lt;- fromJSON(\"data/mc3.json\")\nglimpse(mc3_data)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 60520 obs. of  15 variables:\n  ..$ type             : chr [1:60520] \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" ...\n  ..$ country          : chr [1:60520] \"Uziland\" \"Mawalara\" \"Uzifrica\" \"Islavaragon\" ...\n  ..$ ProductServices  : chr [1:60520] \"Unknown\" \"Furniture and home accessories\" \"Food products\" \"Unknown\" ...\n  ..$ PointOfContact   : chr [1:60520] \"Rebecca Lewis\" \"Michael Lopez\" \"Steven Robertson\" \"Anthony Wyatt\" ...\n  ..$ HeadOfOrg        : chr [1:60520] \"Émilie-Susan Benoit\" \"Honoré Lemoine\" \"Jules Labbé\" \"Dr. Víctor Hurtado\" ...\n  ..$ founding_date    : chr [1:60520] \"1954-04-24T00:00:00\" \"2009-06-12T00:00:00\" \"2029-12-15T00:00:00\" \"1972-02-16T00:00:00\" ...\n  ..$ revenue          : num [1:60520] 5995 71767 0 0 4747 ...\n  ..$ TradeDescription : chr [1:60520] \"Unknown\" \"Abbott-Gomez is a leading manufacturer and supplier of high-quality furniture and home accessories, catering to\"| __truncated__ \"Abbott-Harrison is a leading manufacturer of high-quality food products, including baked goods, snacks, and bev\"| __truncated__ \"Unknown\" ...\n  ..$ _last_edited_by  : chr [1:60520] \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:60520] \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:60520] \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ id               : chr [1:60520] \"Abbott, Mcbride and Edwards\" \"Abbott-Gomez\" \"Abbott-Harrison\" \"Abbott-Ibarra\" ...\n  ..$ dob              : chr [1:60520] NA NA NA NA ...\n $ links     :'data.frame': 75817 obs. of  11 variables:\n  ..$ start_date       : chr [1:75817] \"2016-10-29T00:00:00\" \"2035-06-03T00:00:00\" \"2028-11-20T00:00:00\" \"2024-09-04T00:00:00\" ...\n  ..$ type             : chr [1:75817] \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" ...\n  ..$ _last_edited_by  : chr [1:75817] \"Pelagia Alethea Mordoch\" \"Niklaus Oberon\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:75817] \"Existing Corporate Structure Data\" \"Oceanus Corporations Monthly - Jun '35\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:75817] \"Automatic Import\" \"Manual Entry\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ source           : chr [1:75817] \"Avery Inc\" \"Berger-Hayes\" \"Bowers Group\" \"Bowman-Howe\" ...\n  ..$ target           : chr [1:75817] \"Allen, Nichols and Thompson\" \"Jensen, Morris and Downs\" \"Barnett Inc\" \"Bennett Ltd\" ...\n  ..$ key              : int [1:75817] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ end_date         : chr [1:75817] NA NA NA NA ...\n\n\nThere are 60,520 nodes and 75,817 edges in the data."
  },
  {
    "objectID": "methodology/data_preparation.html#extracting-nodes-and-edges",
    "href": "methodology/data_preparation.html#extracting-nodes-and-edges",
    "title": "Data Preparation",
    "section": "2.1 Extracting nodes and edges",
    "text": "2.1 Extracting nodes and edges\nWe will first extract the nodes and edges.\n\nNodesEdges\n\n\n\nmc3_nodes_raw &lt;- as_tibble(mc3_data$nodes)\nglimpse(mc3_nodes_raw)\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nWe will only retain the following columns:\n\nid: to serve as the identifier for the node\ntype: to differentiate people from companies in the graph.\nProductServices: to identify the products of services a business offer\n\n\nmc3_nodes_lite &lt;- mc3_nodes_raw %&gt;%\n  select(id, type, ProductServices) %&gt;%\n  rename(product_services = ProductServices)\n\n\n\n\nmc3_edges_raw &lt;- as_tibble(mc3_data$links)\nglimpse(mc3_edges_raw)\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nWe will only retain the following columns:\n\nsource: to identify the actor of the relationship, corresponds to id in nodes.\ntarget: to identify the receiver of the relationship, corresponds to id in nodes.\ntype: to identify the type of the relationship\nstart_date: to identify when the relationship started\nend_date: to identify when the relationship ended\n\n\nmc3_edges_lite &lt;- mc3_edges_raw %&gt;% select(source, target, type, start_date, end_date)"
  },
  {
    "objectID": "methodology/data_preparation.html#deeper-look-at-type",
    "href": "methodology/data_preparation.html#deeper-look-at-type",
    "title": "Data Preparation",
    "section": "2.2 Deeper look at type",
    "text": "2.2 Deeper look at type\nBoth the nodes and edges have type which contains the type of the nodes and edges. We will assign a supertype and a subtype from type.\n\nNodesEdges\n\n\n\nmc3_nodes_lite %&gt;%\n  group_by(type) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(-count) %&gt;%\n  kable()\n\n\n\n\ntype\ncount\n\n\n\n\nEntity.Person\n50356\n\n\nEntity.Organization.Company\n7927\n\n\nEntity.Person.CEO\n1293\n\n\nEntity.Organization.FishingCompany\n600\n\n\nEntity.Organization.LogisticsCompany\n311\n\n\nEntity.Organization.FinancialCompany\n23\n\n\nEntity.Organization.NGO\n5\n\n\nEntity.Organization.NewsCompany\n5\n\n\n\n\n\nsupertype - type of entity, either Person or Organization\nsubtype - subcategory of supertype, e.g., Company, FishingCompany, CEO\n\n\n\nmc3_edges_lite %&gt;%\n  group_by(type) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(-count) %&gt;%\n  kable()\n\n\n\n\ntype\ncount\n\n\n\n\nEvent.Owns.Shareholdership\n39378\n\n\nEvent.Owns.BeneficialOwnership\n21531\n\n\nEvent.WorksFor\n14817\n\n\nRelationship.FamilyRelationship\n91\n\n\n\n\n\nsupertype - type of relationship, either Ownership, Employment, Relationship.\nsubtype - subcategory of supertype, e.g., Shareholdership, BeneficialOwnership, FamilyRelationship"
  },
  {
    "objectID": "methodology/data_preparation.html#dates",
    "href": "methodology/data_preparation.html#dates",
    "title": "Data Preparation",
    "section": "2.3 Dates",
    "text": "2.3 Dates\nConsider the date fields, e.g. start_date.\n\nmc3_edges_lite %&gt;% select(start_date) %&gt;% glimpse()\n\nRows: 75,817\nColumns: 1\n$ start_date &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"2028-11-20T0…\n\n\nIt is using the ISO 8601 format that includes the time component. We are only interested in the date component so we will just get the first 10 characters.\n\nsubstr(\"2016-10-29T00:00:00\", 1, 10)\n\n[1] \"2016-10-29\""
  },
  {
    "objectID": "methodology/data_preparation.html#node-aliases",
    "href": "methodology/data_preparation.html#node-aliases",
    "title": "Data Preparation",
    "section": "2.4 Node Aliases",
    "text": "2.4 Node Aliases\nAs the nodes have long names, using them as labels in the visualization is not the best way as the text will cover important information.\nWe will generate them from the first character of each word. We will define a function to provide this capability.\n\nto_initials &lt;- function(name) {\n  strsplit(name, \"[^A-Za-z0-9']+\")[[1]] %&gt;%  # Split when non-alphanumeric\n    substr(1, 1) %&gt;% # Get first letter\n    paste0(collapse = \"\") %&gt;%\n    substr(1, 4) # Get first 4 letters only as some names are still too long\n}\n\n\nto_initials(\"SouthSeafood Express Corp\")\n\n[1] \"SEC\""
  },
  {
    "objectID": "methodology/data_preparation.html#other-considerations",
    "href": "methodology/data_preparation.html#other-considerations",
    "title": "Data Preparation",
    "section": "2.5 Other considerations",
    "text": "2.5 Other considerations\n\nFilteringGraph attributes\n\n\nWe will add an included column to the nodes and edges for filtering purposes so that we can show or hide them depending on the filtering criteria.\nThis is particularly useful in network visualization.\n\n\nWe must also rename the columns for compatibility with igraph and tidygraph.\nFor edges, we will rename source and target to from and to respectively.\nFor nodes, we will rename id to name."
  },
  {
    "objectID": "methodology/data_preparation.html#shaping-the-data",
    "href": "methodology/data_preparation.html#shaping-the-data",
    "title": "Data Preparation",
    "section": "3.1 Shaping the data",
    "text": "3.1 Shaping the data\nWe will now prepare the nodes according to the above considerations.\n\nmc3_nodes_clean &lt;- mc3_nodes_lite %&gt;%\n  rename(name = id) %&gt;%\n  mutate(\n    alias = sapply(name, to_initials),\n    supertype = strsplit(type, \".\", fixed=TRUE) %&gt;% sapply('[', 2),\n    # Get the last type as subtype. In the case of Entity.Person,\n    # both supertype and subtype are \"Person\".\n    subtype = strsplit(type, \".\", fixed=TRUE) %&gt;% sapply(tail, n=1),\n    included = 1\n  ) %&gt;% select(name, alias, supertype, subtype, product_services, included)"
  },
  {
    "objectID": "methodology/data_preparation.html#checking-the-type-fields",
    "href": "methodology/data_preparation.html#checking-the-type-fields",
    "title": "Data Preparation",
    "section": "3.2 Checking the type fields",
    "text": "3.2 Checking the type fields\nLet’s confirm if the types have been mapped correctly to the corresponding supertype and subtype.\n\nmc3_nodes_clean %&gt;%\n  group_by(supertype, subtype) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(-count) %&gt;%\n  kable()\n\n`summarise()` has grouped output by 'supertype'. You can override using the\n`.groups` argument.\n\n\n\n\n\nsupertype\nsubtype\ncount\n\n\n\n\nPerson\nPerson\n50356\n\n\nOrganization\nCompany\n7927\n\n\nPerson\nCEO\n1293\n\n\nOrganization\nFishingCompany\n600\n\n\nOrganization\nLogisticsCompany\n311\n\n\nOrganization\nFinancialCompany\n23\n\n\nOrganization\nNGO\n5\n\n\nOrganization\nNewsCompany\n5"
  },
  {
    "objectID": "methodology/data_preparation.html#checking-the-rest-of-the-data",
    "href": "methodology/data_preparation.html#checking-the-rest-of-the-data",
    "title": "Data Preparation",
    "section": "3.3 Checking the rest of the data",
    "text": "3.3 Checking the rest of the data\nLet’s also inspect the rest of the data if they are in the form we need.\n\nmc3_nodes_clean %&gt;% head() %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\nname\nalias\nsupertype\nsubtype\nproduct_services\nincluded\n\n\n\n\nAbbott, Mcbride and Edwards\nAMaE\nOrganization\nCompany\nUnknown\n1\n\n\nAbbott-Gomez\nAG\nOrganization\nCompany\nFurniture and home accessories\n1\n\n\nAbbott-Harrison\nAH\nOrganization\nCompany\nFood products\n1\n\n\nAbbott-Ibarra\nAI\nOrganization\nCompany\nUnknown\n1\n\n\nAbbott-Sullivan\nAS\nOrganization\nCompany\nUnknown\n1\n\n\nAcevedo and Sons\nAaS\nOrganization\nCompany\nFish, crustaceans and molluscs\n1\n\n\n\n\n\nThe alias was successfully generated based on the node name. The dataframe also has all the columns we need."
  },
  {
    "objectID": "methodology/data_preparation.html#shaping-the-data-1",
    "href": "methodology/data_preparation.html#shaping-the-data-1",
    "title": "Data Preparation",
    "section": "4.1 Shaping the data",
    "text": "4.1 Shaping the data\nWith the previous considerations, we will shape the edge data.\n\nmc3_edges_clean &lt;- mc3_edges_lite %&gt;%\n  rename(from = source, to = target, ) %&gt;%\n  mutate(\n    supertype = ifelse(\n      grepl(\"Event.Owns\", type),\n      \"Ownership\",\n      ifelse(grepl(\"Relationship\", type), \"Relationship\", \"Employment\")\n    ),\n    subtype = strsplit(type, \".\", fixed = TRUE) %&gt;% sapply(tail, n = 1),\n    # Convert date strings to datetime\n    start_date = substr(start_date, 1, 10) %&gt;% as_date(),\n    end_date = substr(end_date, 1, 10) %&gt;% as_date()\n  ) %&gt;%\n  filter(from != to) %&gt;%\n  group_by(from, to, supertype, subtype, start_date, end_date) %&gt;%\n  summarize(weight = n())\n\n`summarise()` has grouped output by 'from', 'to', 'supertype', 'subtype',\n'start_date'. You can override using the `.groups` argument."
  },
  {
    "objectID": "methodology/data_preparation.html#checking-the-type-fields-1",
    "href": "methodology/data_preparation.html#checking-the-type-fields-1",
    "title": "Data Preparation",
    "section": "4.2 Checking the type fields",
    "text": "4.2 Checking the type fields\nLet’s confirm if the types have been mapped correctly to the corresponding supertype and subtype.\n\nmc3_edges_clean %&gt;%\n  group_by(supertype, subtype) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(-count) %&gt;%\n  kable()\n\n`summarise()` has grouped output by 'supertype'. You can override using the\n`.groups` argument.\n\n\n\n\n\nsupertype\nsubtype\ncount\n\n\n\n\nOwnership\nShareholdership\n39378\n\n\nOwnership\nBeneficialOwnership\n21529\n\n\nEmployment\nWorksFor\n14817\n\n\nRelationship\nFamilyRelationship\n91"
  },
  {
    "objectID": "methodology/data_preparation.html#checking-the-rest-of-the-data-1",
    "href": "methodology/data_preparation.html#checking-the-rest-of-the-data-1",
    "title": "Data Preparation",
    "section": "4.3 Checking the rest of the data",
    "text": "4.3 Checking the rest of the data\nLet’s also inspect the rest of the data if they are in the form we need.\n\nmc3_edges_clean %&gt;% head() %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nto\nsupertype\nsubtype\nstart_date\nend_date\nweight\n\n\n\n\n4. SeaCargo Ges.m.b.H.\nDry CreekRybachit Marine A/S\nOwnership\nShareholdership\n2034-12-31\nNA\n1\n\n\n4. SeaCargo Ges.m.b.H.\nKambalaSea Freight Inc\nOwnership\nShareholdership\n2033-04-12\nNA\n1\n\n\n9. RiverLine CJSC\nSumacAmerica Transport GmbH & Co. KG\nOwnership\nShareholdership\n2028-12-02\nNA\n1\n\n\nAaron Acosta\nManning-Pratt\nEmployment\nWorksFor\n2008-07-30\nNA\n1\n\n\nAaron Acosta\nManning-Pratt\nOwnership\nShareholdership\n2008-09-14\nNA\n1\n\n\nAaron Allen\nHicks-Calderon\nOwnership\nBeneficialOwnership\n2025-03-06\nNA\n1\n\n\n\n\n\nThe dates columns only have the date components, not the time. The dataframe also has all the columns we need."
  },
  {
    "objectID": "methodology/data_preparation.html#supernetwork",
    "href": "methodology/data_preparation.html#supernetwork",
    "title": "Data Preparation",
    "section": "5.1 Supernetwork",
    "text": "5.1 Supernetwork\nWe will generate supernetwork containing all the nodes and edges we prepared.\n\nsupernetwork = tbl_graph(\n  edges = mc3_edges_clean,\n  nodes = mc3_nodes_clean,\n  directed = TRUE\n)\n\nWe will save this as an RDS file for use in the Shiny app.\n\nwrite_rds(supernetwork, \"data/rds/supernetwork.rds\")"
  },
  {
    "objectID": "methodology/data_preparation.html#filter-by-subnetwork",
    "href": "methodology/data_preparation.html#filter-by-subnetwork",
    "title": "Data Preparation",
    "section": "5.2 Filter by subnetwork",
    "text": "5.2 Filter by subnetwork\nThe supernetwork is very large and not suitable for visualization as it requires a lot of computing resources to visualize.\nHence, we will create a function that will enable us to focus on the network of a given node. We will define a function extract_subnetwork for this.\n\nextract_subnetwork &lt;- function(graph, node_name, distance=-1) {\n  # negative distance will show full graph\n  node &lt;- which(V(graph)$name == node_name)\n  \n  if(length(node) == 0) {\n    # Return empty graph\n    return(tbl_graph())\n  }\n  \n  distance &lt;- ifelse(distance &lt; 0, length(graph), distance)\n  vertices &lt;- ego(graph, nodes = node, order = distance)[[1]]\n  igraph_subgraph &lt;- induced_subgraph(graph, vids = vertices)\n  nodes_df &lt;- as_data_frame(igraph_subgraph, what = \"vertices\")\n  edges_sf &lt;- as_data_frame(igraph_subgraph, what = \"edges\")\n  tbl_graph(nodes=nodes_df, edges=edges_sf, directed=is_directed(graph))\n}\n\n\n\n\n\n\n\nAbout the function\n\n\n\nThis function generates a subnetwork from a graph based on the nodes in proximity to reference node.\nThe size of the network can be controlled by the distance of the other nodes from the reference node. If the distance is negative, it will include all nodes connected in any way to the reference node.\nIt uses ego from igraph to figure out which nodes are connected within a given distance from a node."
  },
  {
    "objectID": "methodology/data_preparation.html#filter-by-date",
    "href": "methodology/data_preparation.html#filter-by-date",
    "title": "Data Preparation",
    "section": "5.3 Filter by date",
    "text": "5.3 Filter by date\nNext, to enable inspecting temporal patterns, we will filter the edges and nodes based on their existence on the given date.\nWe will define extract_network_snapshot to enable this filtering.\n\nextract_network_snapshot &lt;- function(graph, datestring, delete = FALSE) {\n  date &lt;- as_date(datestring)\n  \n  graph_nodes = as_data_frame(graph, what = \"vertices\")\n  graph_edges = as_data_frame(graph, what = \"edges\")\n  \n  if(is.na(date) || vcount(graph) == 0) {\n    return(graph)\n  }\n  \n  # Assume transition is at 12 AM of given date\n  graph_edges &lt;- graph_edges %&gt;%\n    mutate(\n      included = ifelse(is.na(start_date) | (\n        start_date &lt;= date &\n          (is.na(end_date) |\n             end_date &gt; date)\n      ), 1, 0)\n    )\n  \n  filtered_edges &lt;- graph_edges %&gt;% filter(included == 1)\n    \n  graph_nodes &lt;- graph_nodes %&gt;%\n    mutate(included = (\n      name %in% filtered_edges$from | name %in% filtered_edges$to\n    ))\n  \n  if(!delete) {\n    return(\n      tbl_graph(nodes = graph_nodes,\n                edges = graph_edges,\n                directed = is_directed(graph))\n    )\n  }\n  \n  tbl_graph(nodes = graph_nodes %&gt;% filter(included == 1),\n            edges = filtered_edges,\n            directed = is_directed(graph))\n}\n\n\n\n\n\n\n\nAbout the function\n\n\n\nThis function sets included to true if the edge is active during the given date. For the nodes, they are considered active if they are connected to at least one other node at that point in time.\nThere is also an option to delete the inactive elements altogether, which is useful to calculate measures of centrality on the network structure at that point in time."
  },
  {
    "objectID": "poster.html",
    "href": "poster.html",
    "title": "Poster",
    "section": "",
    "text": "View the original poster here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "The Team",
    "section": "",
    "text": "This project was developed for ISSS608 (Visual Analytics and Applications) during Term 3 of the Academic Year 2023-24 in Singapore Management University by:\n\nKristine Joy Paas\nTan Fengji"
  },
  {
    "objectID": "user_guide.html",
    "href": "user_guide.html",
    "title": "User Guide",
    "section": "",
    "text": "Our Shiny app is hosted at ShinyApps. This guide helps you understand how to use the application."
  }
]