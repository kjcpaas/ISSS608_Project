---
title: "Project Proposal"
format:
  html:
    mermaid: 
      theme: default
---

# Motivation

The motivation for this project stems from the urgent need to combat illegal fishing activities in the sensitive marine ecosystem of Oceanus. FishEye International aims to protect this environment by monitoring and analyzing business activities of commercial fishing operators. This project seeks to enhance the ability of FishEye’s analysts to visualize and understand complex business networks, and further aiding in the detection and prevention of illegal fishing.

# Objectives

This project aims to build an interactive visualization tool to enable FishEye’s analysts to effectively interpret the following changes related to illegal fishing on the business community:

1.  **Temporal patterns and corporate structures**: Highlight temporal patterns and corporate structures changes for analysts to track shareholders over time.

2.  **Business Transactions**: Identify typical and atypical business transactions and infer the motivations behind these activities.

3.  **Network Influence**: Examine how the influence of a company changes over time within the business network.

4.  **SouthSeafood Express Corp Network**: Visualize the network associated with SouthSeafood Express Corp and analyze how the network have changed due to the illegal fishing incident. Identify companies that benefited from SouthSeafood Express Corp’s legal troubles and potentially related transactions.

# Data

The project will examine the data from VAST Challenge 2024 [Mini-Challenge 3](https://vast-challenge.github.io/2024/MC3.html). The data contains the network for Oceanus’s commercial fishing business community. It contains 60,520 nodes, 75,817 edges, and 4,782 connected components.

Each node represents the entities in the fishing business community (including people and organizations). The edges represent the relationship or transactions between each pair of connected nodes.

# Methodology

::: panel-tabset
## Diagram

```{mermaid}
flowchart
  mc3_json[/in: mc3.json/]
  sn_rds[/out: supernetwork.rds/]
  
  read[Read Input]
  clean[Clean Data]
  
  extract_subnetwork[[Extract subnetwork]]
  filter_date[[Filter by date]]
  transform_power[[Transform power graph]]
  
  degree[Calculate degree centrality]
  pagerank[Calculate pagerank centrality]
  betweenness[Calculate betweenness centrality]
  
  plot_corp[Plot corporate structures]
  plot_network[Plot network graphs]
  plot_influence[Plot influence]
  
  combine[/Combine based on requirement\]
  
  clean -- save --> sn_rds
  mc3_json --> read
  
  subgraph Data Preparation
    read --> clean
    clean -.-> extract_subnetwork
    clean -.-> filter_date
    extract_subnetwork --> combine
    filter_date --> combine
    combine -.-> transform_power
    clean -.-> transform_power
  end
  
  subgraph Statistical Analysis
    clean -.-> degree
    combine -.-> degree
    transform_power --> pagerank
    transform_power --> betweenness
  end
  
    
  subgraph Data Exploration & Visualization
    degree --> plot_corp
    pagerank --> plot_influence
    betweenness --> plot_influence
    transform_power --> plot_network
    combine --> plot_network
  end
```

## Explanation

1.  **Data Preparation:** Cleaning and shaping data to what is needed for analysis.

    -   Network and temporal data to enable getting the network state at any given time.
    -   Non-network data for accompanying information, if needed (e.g. products and services)
    -   Writing helper functions to generate the following subgraphs for closer analysis
        -   Getting subgraph based on proximity to a given node
        -   Getting the network state, i.e. nodes and edges present at any given time.
        -   Transforming relationshion graph to power graph for use in calculating influence

2.  **Statistical Analysis:** To apply statistical methods to help in analysis

    -   Calculate degree centrality to identify most active nodes

    -   Calculate measures of centrality to identify influential nodes

        -   **pagerank centrality** for the nodes that hold the most power over resources in the network (the **power holders**).

        -   **betweenness centrality** for the nodes the broker the power of a powerful node over the less powerful ones.

3.  **Data Exploration & Visualization:** To identify patterns in the network and derive inferences from them.

    -   Interactive network graphs to see relationship between entities

    -   Shiny app for users to interact and change parameters for analysis

        -   A time slider will be provided to easily see how the network changes through time

    -   By looking at various network structures, identify the following:

        -   Kinds of business transactions

        -   Influential nodes
:::

# Prototype Sketches

1.  Temporal patterns and corporate structures:

    Create detailed feature timelines that cover various time periods, such as monthly, quarterly, and yearly intervals. These timelines should be meticulously organized to allow analysts to track changes and trends over time effectively. In addition, integrate the corresponding company structures into these timelines to provide a comprehensive view. This integration helps analysts understand the context behind the data and correlating features with organizational changes. By binding the timelines with company structures, analysts can easily identify patterns, pinpoint causes of anomalies, and make informed predictions.

2.  Business Transactions:

    Convert transactions into embeddings using a Large Language Model (LLM) or another suitable encoding framework. This process involves transforming transactional data into a format that captures its semantic and contextual meaning, making it easier to analyze and interpret. Once the transactions are embedded, apply advanced anomaly detection techniques to identify unusual patterns or deviations from expected behavior. These anomalies might indicate potential issues, fraudulent activities, or areas requiring further investigation.

    To understand the motivations behind these anomalies, leverage business heuristics and insights derived from the LLM interpretations. This combined approach ensures a thorough examination of anomalies, enabling more accurate and actionable insights into the underlying motivations and potential implications for the business.

3.  Network Influence:

    Given some specific companies, construct its business network by mapping out the relationships and interactions between various entities. Utilize data sources to construct these connections. Once the network is established, plot the network to visualize the impact of each entity within the network. This visualization helps identify central nodes and influential entities that significantly affect the company's operations and strategic decisions.

4.  SouthSeafood Express Corp Network:

    Based on the previously constructed business network, identify the relevant companies involved in the illegal fishing activity. Begin by analyzing the network to spot entities with suspicious patterns or connections that suggest involvement in illegal practices.

    Once the potentially involved companies are identified, delve into their transaction histories to uncover detailed evidence of their involvement. We can thus map out the methods and routes used for illegal fishing operations.

# R Packages

-   [tidyverse](https://www.tidyverse.org/): A collection of R packages used in data science, which includes [ggplot2](https://ggplot2.tidyverse.org/), [tibble](https://tibble.tidyverse.org/), [readr](https://readr.tidyverse.org/)
-   [vistime](https://github.com/shosaco/vistime): For visualizing timelines
-   [ggraph](https://ggraph.data-imaginist.com/): Extension of `ggplot2` for plotting relational data
-   [visNetwork](https://datastorm-open.github.io/visNetwork/): For plotting interactive network visualizations, compatible with Shiny
-   [jsonlite](https://cran.r-project.org/web/packages/jsonlite/index.html): For parsing JSON data

# Project Schedule

```{r}
#| code-fold: true
#| warning: false
#| code-summary: "Show code"
pacman::p_load(vistime, ggplot2)
data <- read.csv(text="event,group,start,end,color
                       ,Project Proposal,2024-05-12,2024-05-26,#a5d6a7
                       ,Exploratory data analysis,2024-05-12,2024-05-26,#a5d6a7
                       ,Exploratory data analysis,2024-05-26,2024-06-16,#DD4B39
                       ,R Quarto/ Netlify,2024-05-12,2024-05-26,#a5d6a7
                       ,R Quarto/ Netlify,2024-05-26,2024-06-30,#DD4B39
                       ,R Shiny App,2024-05-26,2024-06-30,#DD4B39
                       ,Poster,2024-06-16,2024-06-30,#DD4B39
                       ,User Guide,2024-06-20,2024-06-30,#DD4B39"
                 )
                
proposal_deadline <- as.Date("2024-05-26") 

p <- gg_vistime(data, title = "Project Timeline") 
p +
  geom_vline(xintercept = as.numeric(as.POSIXct("2024-05-26")), color = "red", size = 1)
```
